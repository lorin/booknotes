# Mission Improbable

Book by Lee Clarke

# Big ideas

- must look beyond individuals to understand role of organization
- collective memory
- telling stories
- uncertainty creates unease
- work-as-imagine
- apparent affinities
- Power and rhetoric in technical orgs
- expertise requires experience
- technical language hides subjectivity
- technical documents have a symbolic function
- Organizations are more effective at dealing with incidents than individuals
- organizations have collective memory
- organizations try to transmute uncertainty into risk

# Themes 

- Experts and where they are wrong
- Organizations play an enormous role
- The political nature of work that is couched in technical term
- Persuasion as one of the function of planning documents
- Struggle/conflict/negotiation
- Organizations work to transform uncertainty into risk by using analysis

# Terms

- **acceptability of risk** (p101, p158)
    - value-laden, political, based on choice
- **all-hazards:** preparing for one type of hazard is similar to preparing for another type (p74)
- **apparent affinities** (p14, p71)
    - idea that a potential catastrophe is similar enough to an event that has happened in the past that we can plan effectively to deal with it
- **assessment of risk** (p158)
    - seen as objective, technical, facts, value-free
- **C-shibboleths** (p56)
    - the things that are always blamed when disaster response goes poorly
        - coordination
        - communication
        - cooperation
- coherent (p17)
- collective memory (p7)
- control (p153)
- __declaratory policy__ (p90): what leaders say in public
    - contrast with their actual actions
- disqualification heuristic - tendency for experts to discount evidence that conflicts with their preexisting beliefs about the safety of a sociotechnical system (p107)
- esoteric knowledge (p128)
- fantasy documents (p2)
- history (p7)
- ideology (p70)
- instrumental value (p16, p73)
    - contrast with symbolic value
- interactive (p41)
- interpret (p87)
    - used to describe how people will react to pronouncements by authority figures during a novel emergency situation, like a nuclear meltdown
- mundane (p87)
    - see apparent affinities
- negative externalities (p23)
- nonspecial (p87)
    - see apparent affinities
- **operational rationality:** when operators can turn uncertainty into risk so that they can control the problem (p66)
- organizations (p4, p5)
- plans
- political constructionist view (p101)
- rationality badges (p16)
- realism doctrine (p116) - people would behave properly in a real emergency, even if they refused to participate in a drill
- role conflict (P87)
- rhetorical (p2)
- social (p41)
- socially construct (p5)
    - risk
    - danger
    - safety
- symbolic planning (p2, p13, p73)
- **__theory of good planning__:** planning improves effectiveness of response (p49)
- **Western rationalism:** expert knowledge can be brought to bear to control situations (p68)

# Chapter 1: Some functions of planning

## Planning is prosaic
- p2
- theme of book: the function of a disaster recovery plan is for the org to convince people of something
- functional is __rhetorical__
- these are __fantasy documents__
- p4
- under high uncertainty, planning becomes __rhetorical__, __symbolic__
- becomes marketing: trust us, we can control these events

## The relevance of organizations
    - The __organization__ is the right unit to think of then considering disaster response
- p5
- orgs create plans
- orgs are the ones that __socially construct__ risk, danger, safety
- p6
- orgs are better able to deal with disasters than individuals because
    - they have more resources
    - they can coordinate
    - they can split into smaller orgs
- p7
- orgs have __collective memory__, which enables them to do better than individuals
- History is captured in:
    - stories that are passed down
    - docs
    - processes of the org
- orgs are able to leverage the experiences of multiple individuals
- therefore, orgs have potential to learn more than individuals do

## Functional planning
- functional planning is when
    - we have history to draw on
    - we can estimate probabilities of the success of the plan
- plans can be useful because we can estimate costs, which makes it easier for management to allocate resources
- planning reduces the uncertainty that management needs to deal with

## Transforming uncertainty into risk
- p11
- James Marin & Herb Simon:
    - risk: when you know the probability distribution of outcomes
    - uncertainty: when you don’t know the probabilities
- organizations try to convert uncertainty into risk by using analysis
- society expects organizations to be able to control uncertainty
- p12
- organization leaders don’t want to admit that they are unable to do this
- there are pressures both inside and outside of the organization to transmute
- __time __and __chance __into __classification__ and __command__

## Symbolic planning
        - p13
        - some orgs use planning as __signalling__
            - they collect info but they don’t really act on it
        - making a plan acts as a claim of expertise
        - because claims fo expertise exclude non-experts from the process, planning is inherently political
        - fantasy documents try to turn the following uncertainties into risk: 
            - how future events will unfold 
            - how future agents will react to to those events
        - p14
        - __apparent affinities__ - the idea that a potential future catastrophe is similar enough to something that has occurred in the past that we can plan effectively to deal with it
        - Examples of fantasy documents, plans for…
            - recovery after general nuclear war
            - evacuation after (or during) a total meltdown of the Shoreham nuclear power station on Long Island
            - containing and cleaning up massive oil spills
            - 

# Chapter 2: Fantasy documents
    - p16
    - The function of an instrumental plan is to set out a design description for acting and coordinating
    - the function of a symbolic plan is to communicate to others, “we can actually control these uncontrollable things”
    - author calls them “fantasy documents” because either they can’t keep the promises they make, or there’s no way for us to know that they could
    - they act as __rationally badges__: “we are in control”
    - when fantasy docs are accepted as legitimate, they function as a constraint on political debate, because they provide consensus-accepted language which sets the terms of the debate
        - shapes, frames the debate
        - they reinforce systems that “seem increasingly beyond our comprehension and control”
    - they’re like a TV script, describing work-as-imagined of agents in the wake of a disaster
    - p17
    - docs are __coherent__ and clear about unfolding of events
    - no ambiguity
    - p18
    - docs describe a closed system
        - cf. Object-world is hard to get out of
    - p19
    - managers need to __do something__ about potential disasters
    - three sets of docs covered in this book
        - major oil spill cleanups
        - civilian nuclear plant evacuations
        - civil defense & post-nuclear war survival

## Oil spill fantasies
        - p21
        - every cleanup attempt of major oil spills has failed to recover more than a small fraction of the spilled oil
        - p23
        - Newfoundland experiment demonstrates that cleanup is basically impossible
        - plans are symbolic, they show that orgs can manage __negative externalities__ of large-scale oil production
        - oil spill planning docs shape the debate around the “problems” of
            - insufficient money
            - lack of determination
            - poor coordination
        - this means that certain topics don’t even get discussed:
            - conservation
            - corporate power
            - political risk

## Radiation fantasies
        - p24
        - Example: Shoreham nuclear power plant on Long Island
        - plant was never completed
        - perceived danger was not a meltdown itself but risk of not being able to evacuate Long Island
        - p25
        - power company argued that response would be similar to non-nuclear disasters
            - people wouldn’t panic
            - emergency responders would do their job
        - critics argued that evacuation workers would focus on protecting their families first
        - p27
        - describes what went wrong during evacuation exercise
            - bus evacuations didn’t work as expected
            - p28
            - emergency broadcast system messages were confusing, contradictory
            - p29
            - large latency between information request and response
            - traffic guides very late
        - p30
        - disasters that were never planned for
            - Three Mile Island
            - Chernobyl
            - Bhopal
            - Challenger
            - Exxon Valdez
        - the fantasy is that
            - most of the elements of the plan will actually work as expected
            - we can know in advance what the different bad scenarios are
            - we can prepare effectively for them
## Nuclear war fantasies
            - p31
            - post office post-nuclear war contingency plan
            - p34
            - FEMA evacuation plan
            - p35
            - claim: 80% of the population could be saved in the wake of a nuclear attack
                - original source: 1978 Presidential Directive 41
                - no evidence provided to support the claim
            - pp36-37
            - 80% number takes on life of its own
            - pp38-39
            - people generally don’t panic in natural disasters, but they also have trouble coordinating
                - e.g. argue over jurisdiction
            - p40
            - civil defense plans assume existence of social order, but after a nuclear attack, there would be chaos
## Symbols and uncertainty
            - p41
            - planning is __interactive__, __social__
            - planners have analyzed the problem, and they can handle it
            - audiences:
                - oil spill - regulatory agencies
                - civil defense post nuclear war - state and local government agencies
                - civilian nuclear power - the courts
            - fantasy docs are most likely when they written in support of
                - very large scale systems
                - newly scaled up systems
            - p42
            - insiders become overconfident
            - outsiders feel safe
        - 
# Chapter 3: Planning the C-Shibboleths
    - p43
    - fantasy means: we cannot know the likelihood that a plan will succeed or fail
    - p44
## Non-fantasy planning
        - p47
        - All plans have a symbolic role
            - e.g. syllabus is an instrumental plan that also serves to establish the authority of the professor
## The theory of good planning
## Texas City explosions
        - p48
        - Two ships blew up in two days (April 16 and 17, 1947)
        - first ship (The __Grandcamp__)  held fertilizer
        - second ship (The __High Flyer__) was close by, caught fire 16 hours later
        - p49
        - no plan existed for a coordinated response
        - a contingency plan would’ve likely helped
## Chernobyl catastrophe
        - evacuation only started 36 hours after accident
        - general population was not informed about the accident until the evacuation
        - no evacuation plan in place before accident
        - **__theory of good planning__:** planning improves effectiveness of response
## Miamisburg train wreck
        - p51
        - train wreck carrying chemicals, big fire
        - initially, jurisdiction fight between trainmaster and firechief
        - local officials took control and executed existing plan
        - p52
        - response was effectively managed, good coordination
## World Trade Center Bombing & 1993 Snow storm
        - Feb. 1993: WTC Bombing
        - Mar. 1993: NJ snow storm
        - effectively executed emergency management plans
## Livingston train wreck
        - p53
        - contingency plan helped make evacuation effective
        - p54
        - good coordination among different orgs
        - p55
        - no jurisdictional rguments
        - effective flow of information
## The C-Shibboleths
        - p56
        - the things that are always blamed when disaster response goes poorly
        - The three C-Shibboleths are:
            - co-ordination among organizations
            - communication among people who need information
            - co-operation among individuals and organizations
        - these are always discussed in accident accounts
## Planning sometimes fails us
        - p57
        - planning is not always related to outcomes
            - sometimes there are plans and poor outcomes
            - sometimes there are no plans and good outcomes
## The case of the worst case
        - p57
        - sometimes responders are overwhelmed (saturated!) by events
            - saturation
### Washington D.C.’s worst case
            - big snowstorm
            - OPM closed government offices 3 hours early because of the snow
            - a plane leaving DCA had ice and snow on the wings, it crashed into a bridge that connects DC and VA
            - traffic was high due to the early closing
            - rescue workers had trouble with thick ice in the river
            - 25 minutes after the crash, there was a Metro crash @ Smithsonian stop
            - some rescue workers were rerouted to Metro
            - p60
            - who could have foreseen two concurrent accidents under heavy traffic and horrible weather conditions?
            - they had plans in place for
                - airplane crash
                - emptying out DC
                - subway crash
            - but they didn’t plan for all three happening at the same time!
## Accidental success
        - p61
### Ohio River Flood
            - 1937 - Ohio River flooded
            - 11 cities on the river were evacuated effectively, even though there weren’t evac plans in place
### Duluth train wreck
            - p62
            - train carrying toxic chemicals derailed
            - there was a disaster plan in place, but it was not activated
            - local officials worked effectively together
            - people found out about the danger and evacuated on their own
            - p63
            - hypothesis: people had prescience experience with evacuations due to history of accidents in the area
            - the people __remembered__ how to evac
### Three Mile Island
            - there was not a pre-existing plan for evac’ing nearby population
            - plan had been written, but not approved
            - p64
            - Emergency orgs (NRC, FEMA) didn’t want to tell people what was happening
            - people didn’t trust federal, state, utility authorities
            - people evac’d on their own, didn’t panic
            - no official co-ordinated response
## Planning, experience, and symbolism
        - p66
        - __operational rationality:__ when operators can turn uncertainty into risk so that they can control the problem.]
            - Examples:
                - plans are designed to dump fuel in flight
                - cargo ship splits up the hold into cells such that, if the ship hits the rocks, it does not spill all of its cargo
        - p67
        - operational rationality is based on relevant experience
        - p68
        - we want to believe planning leads to better outcomes because we believe in **Western rationalism:** expert knowledge can be brought to bear to control situations
        - we don’t know when planning works and when it doesn’t
        - if planning is not directly related to response effectiveness, harder to assess
            -  why systems break down
            - role of expert knowledge
        - 
# Chapter 4: Apparent affinities: normalizing danger through simile
    - p70
    - problem with plans for scenarios like oil spills and nuclear power plant area evacuations is that they claim future events are knowable/controlable in circumstances where we don't have reason to believe they are knowable/controlable
    - they are more __ideology__ than __knowledge__
    - experts aren't really allowed to say
        - there's no way of knowing (e.g., post-nuclear-war scenario)
        - it can't be done (e.g., large oil spill cleanup)
## Apparent affinities
        - p71
        - __Apparent affinities__ between two categories of entities is a claim that the two categories are essentially the same
            - knowing about one of them means we know about the other one
        - p73
        - rationality is both
            - instrumental: we use it to solve problems
            - symbolic: we use it to convince others that we can solve problems
        - p74
        - post-nuclear scenarios: apparent affinity is claimed through the __all-hazards__ concepts
            -  preparing for one type of hazard is similar to preparing for another type
        - Shoreham (Long Island Power): apparent affinity between evacuation and commuting
            - "Long Island evacuates five times a week" experts
        - large oil spills: apparent affinity to small spills
## Oil spills and ecological fallacy
        - ex: Exxon Valdez
        - p75
        - there were five spill contingency plans
        - this book focuses on one plan: written by the pipeline company
        - plan itself was not very detailed
        - p78
        - assumed good communications and coordination between agencies
        - estimated 50% oil recovery
        - assumes close to best-case weather conditions
        - p82
        - company basically updated smaller spill plan for larger spill
## Civilian Nuclear Evacuation & the Suburban Condition
        - Shoreham nuclear power station in Long Island was cancelled, after construction had completed on the plant, because power company failed to convince the public that Long Island could be effectively evacuated in an ermergency
        - p83
        - opponents won by shifting the narrative from discussion of __probabilities__ of failure to __possibilities__ of bad outcomes
            - harm to children & homes
        - supporters argued: meltdown is like an ice storm
            - Long Island knows how to handle an ice storm
        - opponents argued: evacuation is inherently impossible
## Meltdowns are ordinary
        - p84
        - supporters claim: people would follow the evacuation plan
        - opponents claim:
            - people would __overinterpret__ what officials said
            - evacuation workers wouldn't show up to perform their duties
            - evacuation wouldn't be effectively controlled
            - ther emight be cahos
        - p85
        - surveys showed that people would prioritize keeping their families safe over following their roles in an evacuation
            - e.g., bus drivers
        - power company experts said that 
            - surveys were not good predictors of real behavior
            - they knew from scientific research how people tend to respond during similar events
        - experts claimed that it didn't matter what "the public" would do, because plans are carried out by __organizations__, not the public
        - experts also noted that emergency workers were historically effective
            - in previous emergencies, they didn't abandon their posts to care for their own families 
        - p86
        - the plan depended on school bus drivers evacuating kids from schools in the affected area to a community center in a neighboring county
            - assumed that these drivers would not focus on their own families, and would drive into the "hot zone"
            - school bus drivers are not traditional emergency workers
        - p87
        - opponents focused on the __role conflict__ the bus drivers
        - supporters tried to cast meltdown (which we have no experience with) as akin to natural disasters and commuting (which we do have experience with)
            - nonspecial
            - mundane
        - opponents: people interpret nuclear accidents differently than natural disasters
## Civil defense and dual-hazards planning
        - p90
        - In the 60s, U.S. gov't claimed they could save 80% of people in nuclear war
        - __declaratory policy:__ what leaders say in public
            - as opposed to what they actually do
        - p91
        - U.S. government never invested in fallout shelters for the population, indicates they weren't planning for fallout shelters as a defense mechanism
        - p93
        - U.S. strategy switched to evacuation, but:
            - warning time for a nuclear strike might be measured in minutes
            - enemy could retarget inbound missiles to hit sites where populace was evacuating to
            - would there even be somewhere to return to after the evacuation?
        - these concerns were never addressed
        - experts would have had to admit they had no idea if the proposed civil defense plans would work
        - government crated an __apparent affinity__ to natural disaster planning
        - p94
        - they actually combined nuclear civil defense and natural disaster planning into one thing.
        - terms for this
            - dual-planning
            - all-hazards planning
            - full spectrum preparedness
        - the new Defense Civil Preparedness Agency started in the 70s had an explicit dual-planning mandate for both civil defense and natural disasters
        - p97
## Risk similes and normalization of danger
        - p98
        - apparent affinities enable prediction, transmute uncertainty into risk
        - p99
        - when orgs don’t have real control, they create symbolic control through planning
        - first, have to define “The Problem” 
        - experts must establish experience so that people will have confidence in them
    - 
# Chapter 5: Authority and audience in accepting risk
    - p101
    - __political constructionist view__: the role of power in the process that transforms uncertainty to risk
    - __acceptability of risk__ is always a moral judgment
        - not objective!
        - contrast with object world
        - always judged with respect to an arbitrary standard
    - p102
    - must establish authority via expertise in order to successfully justify their standard
    - also need to convince others
## Experts, organizations, and social conflict
        - experts bridge the gap between an organization and its constituents that live outside of the organization
        - experts take political judgments and couch them in technocratic, “value-free” (neutral) terms
            - they do value-laundering
        - experts get authority from organization affiliation
            - consequence: organizations influence experts
        - ideas the author borrows from other fields:
            - from study of orgs: organizations are the man agents that create danger
                - we can’t ignore their influence in our analysis of dangers
            - from sociology: symbols, including fantasy documents, are developed through negotiation (social construction)
            - rhetoric: the envisioned audience influences the shape and content of the fantasy document
                - to understand fantasy docs, we must understand the audience
## Power in Alaska
        - There are two ways that political power influenced spill response planning docs in Alaska
            - 1. Role of oil in political economy
            - 2. Negotiations over jurisdiction and profits
## Institutional context of fantasy
        - p105-106
        - story of how Alaska ended up with a pipeline->tanker transport system instead of a pipeline that passed through Canada (role of politics)
        - most of the oil company’s spill plan related to pipeline spills
            - but the pipeline part of the transport is safer than the tanker part
            - land spills are easier to clean up than open water spills
## Microstruggles
        - p107
        - **disqualification heuristic **- tendency for experts to discount evidence that conflicts with their preexisting beliefs about the safety of a sociotechnical system
        - apparent affinity between small spill cleanup and large spill cleanup traces back to historical conflict between the oil company and the Alaska Department of Environmental Conservation (ADEC)
        - enforcing more realistic planning for large oil spills was de jure within ADEC's scope but de facto was not
## Federalism on Long Island
        - p110
        - locals fought against Long Island nuclear plant by refusing to participating in the emergency planning process
        - by doing so, they effectively vetoed the plant
        - p111
        - there wasn't a single expert authority making estimates about worst-case scenarios, instead there were multiple experts making conflicting estimates
            - estimates from power company estimates conflicted with county experts
        - pp112-113
        - power company ran an evacuation exercise, but state and local governments refued to participate
        - p116
        - __realism doctrine__ - when it comes to a real emergency, state and local agencies will participate properly in the evacuation plan, if they don't take part in the simulated exercises
            - this was assumed by the power company to justify the success of the evacuation exercises even though local agencies didn't participate in them
## Local wisdom and civil defenece
        - p120
        - polls showed that people didn't believe in civil defence
        - p125
        - rhetoric changed from nuclear defense to emergency preparedness (apparent affinity)
        - Federal Emergency Management Agency (FEMA) focused on dual hazards, people supported emergency prepardness
## Power and rhetoric
        - p127
        - We overestimate the role of intent on the effects that systems have
        - many outcomes are not intended
        - even the most powerful aren't good enough at reasoning about the feature that outcomes are due to their intent
        - intention of the planners does not give us insight into how orgs use planning docs
        - docs don't emerge fully formed, they do so incrementally, through power struggle/conflict
## Producing expertise
        - p128
        - nobody has experience with things like nuclear war
        - the ways you become perceived as an expert are
            - 1. appearing to have esoteric knowledge
            - 2. not contradicted by other potential experts
        - p129
        - no real research to draw on for reasoning about disaster that have never happened (nuclear war)
        - simulate and extrapolate based on unverifiable assumptions, then cite those findings
        - p130
        - professors built models of evacuation, these took on rhetorical power
        - demonstrated expertise (we can model this!)
## Muting other voices
        - power company failed to establish sole voice of expertise
            - too much visible disagreement with other experts
        - true expertise requires
            - experience
            - conceptualization
            - understanding
        - p133
        - once experts cement tehir status, issues around values are discussed as technical issues
            - e.g., are the backup systems sufficient?
        - before this happens, there is social conflict (negotiation?) over who gets to determine the framing
        - p134
        - rhetoric of technical expertise tends to win out over community, democratic expression of opinion
        - expertsie is socially and politically constructed, results from power struggle
            - what alternative ways of knowing are excluded?
# Chapter 6: Organizations, symbols, publics
    - p135
    - fantasy docs aren't useful as blueprints for action, but to 
        - convince people
        - make them feel better about risks
        - protect the organziation
    - the docs are symbols of expertise
    - organizations tend to address new problems the way they did previous ones
    - you get fantasy docs when the new problem being addressed is too different from the old ones that the solutions are based on
    - want to transform uncertainty into risk
    - fantasy docs convince others that you have done so
    - p136
    - orgs put "civil defense" and "city evacuation" in the same category
    - they socially construct the categories and how different things fall into them
    - they make too many assumptions
    - planning itself is a claim about expertise
## Rhetoric and the Public
        - p137
        - fantasy documents are tools to convince an audience that the authors have expertise
        - written by professionals
        - culture dictates who is inside vs outside the profession
        - p138
        - document's language is shaped by intended audience
        - p139
        - audience for docs is typically other organizations
            - regulators
            - courts
            - state and local governments
## Why do they do it?
        - p140
        - are authors of fantasy documents lying?
## The question of deception
        - p141
        - not lying, but effect of them is misleading
        - not creating a reality that the authors don't believe, but creating a reality that authors also believe
## Psychological need and pathology
        - p143
        - psychological need for control isn't enough to explain fantasy docs
        - p144
        - need to understand the forces at work inside of organizations
## Political palliative
        - p145
        - Edelman's theory:
            - fantasy docs reassure the public
        - Brunsson's theory
            - political orgs have to satisfy multiple, conflicting interests, so they say one thing and do another
        - p148
        - there are limits to social construction
## Managerial imperative
### The environment
            - p150
            - environments constrain what organizations can do
            - relationship to fantasy docs:
                - 1. the environment contains the audience, and the audience shapes the document
                - 2. the environment is composed of other organizations
                    - rhetoric is aimed specifically at organizations
                - 3. plans emerge from social conflict/struggle
### Professions
            - p151
            - hot air balloon metaphor for influence of management on organization
                - can nudge in a direction, but also subject to weather
                - https://twitter.com/norootcause/status/1416923508001546242
            - p152
            - managers need to project that they are leading in situations with a lot of uncertainty
            - they fall back to what they know how to do, what problems they know how to manage
            - p153
            - managers implicitly assume that all problems are manageable, that situations can be __controlled__
            - p154
            - all risks are controllable (they think)
            - p155 this is part of the profesionnal culture of management
## Expert knowledge
        - p158
        - general view is
            - __assessment__ of risk is technical, objective, value-free facts
            - __acceptability__ of risk is value-laden, political, choice
        - author claims assessment is also political, value-laden
### Experts and prediction
            - all experts make predictions
            - p162
            - experts predict well when their models are based on experience and history
### When experts err
            - experts make mistakes when
                - they're missing important knowledge
                - they only apply experience to cases where it isn't applicable
                - p164
                - they apply methods b/c they are are familiar with them, rather than because the method is the best one to use given the circumstances
            - p165
            - experts influenced by organizational factors
                - production pressure
                - power struggles
                - political interests
## Ending reflections
        - p166
        - fantasy docs appear in
            - impossible goals (e.g., zero accidents)
            - novel situations (e.g., post-nuclear war)
            - scale-up of known situations (e.g., big oil spills)
        - these scenarios are all cases where we are missing the relevant history/experience to draw upon
### Normalizing danger
            - p167
            - Fantasy documents set the terms for discussing dangers
            - p168
            - planning processes contain embedded theory on how organization works
            - fantasy documents noramlize danger - "it's under control"
            - p171
            - opposite of fantasy document: honest about dangers and uncertainty
