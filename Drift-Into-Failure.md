# Drift into Failure: From Hunting Broken Components to Understanding Complex Systems

Sidney, Dekker

## Terms

complexity, drift, failure, broken part, Newton-Descartes, diversity, systems
theory, unruly technology, theory, rational, rational choice theory,
decrementalism, relationships, high-reliability organizations, normalization of
deviance

local rationality principle: people are doing what makes sense given the situational indications, operational pressures, and organizational norms existing at the time.

Systems thinking is about relationships, not parts

Five concepts that characterize drift:

* scarcity and competition
* Decrementalism, or small steps
* Sensitive dependence on initial conditions
* Unruly technology
* Contribution of the protective structure

Banality of accidents thesis: incidents do not precede accidents. Normal work does.

Four ingredients of high reliability organizations:

1. Leadership safety objectives
2. The need for redundancy
3. Decentralization, culture and continuity.
4. Organizational learning (incremental learning through trial and error).

## Highlights

- drift occurs in small steps
- complex systems are sensitively dependent on initial conditions
- complex systems that can drift into failure are chaaracterized by unruly technology
- System thinking is about relationships, not parts
- Safety certification is about bridging the gap between a piece of gleaming new
    technology in the hand now, and its adapter, coevolved, grimy, greased-down
    wear and use further down the line.
- Incidents do not precede accidents. Normal work does.
- The so-called common-cause hypothesis (which holds that accidents and
    incidents have common causes and that incidents are qualitatively identical
    to accidents except for being just one step short of a true or complete
    failure) is probably wrong for complex systems.
- In high-reliability organizations, active searching and exploration for ways
    to do things more safely is preferred over passively adapting to regulation
    or top-down control
- Continuous operations and training, non-stop on-the-job education, a regular
   throughput of new students or other learners, and challenging operational
   workloads contribute greatly to reduced error rates and enhanced reliability.
- Smaller dangers are courted in order to understand and forestall larger ones.
- Instead [a belief about the possibility to continue operating safely] should be a belief that is open to intervention as as to keep it curious, open-minded, complexly sensitized, inviting of doubt, and ambivalent toward the past.
- [Reaching and staying at a high-reliability end-state] involves a
    preoccupation with failure, a reluctance to simplify, a sensitivity to
    operations, deference to expertise and a commitment to resilience.
- It also is an active consideration of all the places and moments where you
    don't want to fail.
- High-reliability theory suggests that it is this complexity of possible
    interpretations of events that allow organizaitons to better anticipate and
    detect what might go wrong in the future.
- These decisions are sound when set against local judgment criteria; given the
    time and budget pressures and short-term incentives that shape behavior.
    Given the knowledge, goals, and focus of attention by the decision-makers,
    as well as the nature of the data available to them at the time, it made
    sense.
- One of the ingredients in almost all stories of drift is a focus on production
    and efficiency.
- Recall Weick's and Perrow's warning: what cannot be believed cannot be seen.
- It is this insidious delegation, this handover, where the internalization of
    external pressure takes place.
- Instead, the processes by which such decisions come about, and by which
    decision-makers create their local rationality, are one key to understanding
    how safety can erode on the inside a complex socio-technical system.
- "normalization of deviance"
- The solution to risk, if any, is to ensure that the organization continually
    reflects critically on and challenges its own definition of "normal"
    operations, and finds ways to prioritize chronic safety concerns over acute
    production pressures.
- The idea that organizations are capable of inculcating a safety orientation
    among its members through recruitment, socializing and indoctrination is met
    with great skepticism.

## Outline

1. Failure is always an option
    - Who messed up here?
    - Rational choice theory
    - Technology has developed more quickly than theory
    - The Gaussian copula
    - Complexity, locality and rationality
    - Complexity and drift into failure
    - A great title, a lousy metaphor
    - Why we must not turn drift into the next folk model
2. Features of drift
    - The broken part
    - Unanswered questions
    - The outlines of drift
    - Scarcity and competition
    - Decrementalism, or small steps
    - Sensitive dependency on initial conditions
    - Unruly technology
    - Contribution of the protective structure
    - A story of drift
3. The legacy of Newton and Descartes
    - Why did Newton and Descrates have such an impact?
    - So why should we care?
    - What Newton can and cannot do
    - Columbia: parts that broke in sequence
    - Broken part, broken system?
    - Accidents come from relationships, not parts
    - We have Newton on a retainer
4. The search for the broken component
5. Theorizing drift
6. What is complexity and systems thinking?
7. Manging the complexity of drift


## Failure is always an option

Features of complex systems

1. Complex systems can exhibit tendencies to drift into failure because of uncertainty and competition in their environment. Adaptation to these environmental features is driven by a chronic need to balance resource scarcity and cost pressures with safety.
2. Drift occurs in small steps.
3. Complex systems are sensitively dependent on initial conditions.
4. Complex systems that can drift into failure are characgerized by unruly technology.

## Features of drift

### Unanswered questions

Systems thinking is about relationships, not parts

System thinking is about the complexity of the whole, not the simplicity of
carved-out bits. Systems thinking is about non-linearity and dynamics, not about
linear cause-effect-cause sequences. Systems thinking is about accidents that
are more than the sum of the broken parts. It is about understanding how
accidents can happen when no parts are broken, or no parts are seen as broken.

### Outlines of drift

Five concepts that characterize drift:

- scarcity and competition
- Decrementalism, or small steps
- Sensitive dependence on initial conditions
- Unruly technology
- Contribution of the protective structure

### Scarcity and competition

This moved Langewiesche to say that Murphy’s law is wrong: everything that can
go wrong usually goes right, and then we draw the wrong conclusion.

### Sensitive dependency on initial conditions

Safety certification is about bridging the gap between a piece of gleaming new
technology in the hand now, and its adapted, coevolved, grimy, greased-down wear
and use further down the line.

### A Story of drift

This is the banality of accidents thesis. These are not incidents. Incidents do
not precede accidents. Normal work does. In these systems:

> accidents are different in nature from those occurring in safe systems: in this case accidents usually occur in the absence of any serious breakdown or even of any serious error. They result from a combination of factors, none of which can alone cause an accident, or even a serious incident; therefore these combinations remain difficult to detect and to recover using traditional safety analysis logic. For the same reason, reporting becomes less relevant in predicting major disasters.

